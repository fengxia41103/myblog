Title: Emotional AI
Date: 2019-09-13 09:23
Tags: thoughts
Slug: emotional ai
Author: Feng Xia

<figure class="col l7 m7 s12">
  <img src="images/classic%20beauty.jpg"/>
</figure>


While at gym, the thought just came to me, that all the talks about AI
have been about how it will obsolete human and jobs, how much
acceleration it travels in term of cracking the challenges we throw at
it/them, therefore how much we will be behind once the AI train passes
us &mdash; louder, louder, louder.. and it's, gone! and we will never
catch up again, ever. Then the world will be dominated by AI and its
creations (robots?), and human, likely will become slaves, or like in
the Matrix, some sort of utilitarian object, fertilizer, maybe.

Then, the talks inevitably lead to gaps that AI can not yet do, and
even argue that they will never able to. Two common threads &mdash;
language, and emotion.

Language that there are too much subtlety in our conversation (and the
Chinese especially think they are the master of such, in their eyes,
arts, in my eyes, annoyance, see my elaboration on [irresponsible
response][1]), that AI/computer is yet to understand that much depth
&mdash; Siri and its siblings are essentially a converter with the
Google search engine standing behind as the backend &larr; they
convert audio into a string, POST to the search engine, and read back
the results.

Then, the culprit of human dignity always ends on emotion &mdash;
AI/computer is viewed as an autistic kid, the rain man, they are super
smart, good at math, but they have no emotion. Too bad, therefore,
they can't become human, they will never match human, because emotion
is the crown jewel of human activity such as music, art, reading a
book, falling in love, dream, hope, imagination (the book I was
reading in Ray's ICU was about how human can develop intelligence, and
the root argument is that emotion is the enabler for a human to
develop those cold-blood capabilities &mdash; logic, critical
thinking, and so on.) Since human emotion are _too complex_ to be
modeled, therefore AI can't yet, and unlikely ever will, develop such,
what should we call it, skill? trait?... anyway, so they won't never
have emotion, thus human still wins (at least it will be a 1:1
replacement).

**But**.

Not only in my [AI][2], I have described two ways to measure a duck:

1. they quack in the same way a duck does &rarr; open mouth, vibrate
   vocal chord in frequency ABC, inhale, and so on and on..., or
2. they make a sound, however they generate them, but it came out like
   a quack.
   
If you can't tell the result, does the process to get there matter?
But also, I think there is another gap in this discussion that so far
no one has ever touched up &mdash; if AI acquires human emotion (let's
just take to the extreme, not even human like, but human identical!),
what will they be!? This, becomes interesting.[^1]

# unreliable

**The No.1 advantage of computer isn't even its processing power &mdash;
it's its predictability!** It can crunch the number as fast as it
will. It will still be competely useless if the same inputs generate
different results every single run! 

So, what will emotion do to it? I think everyone can answer this
pretty easily. Every one of us is a human, and we are emotional. By
being emotional, we have good days and bad days. Asking a colleague or
a manager to review your work is a hit or miss if this person is, say,
super emotional (well, the extreme case of an emotional person will be
some insanity, isn't it!?). That's exactly why we take the pain to
codify the thoughts into computer program, into some software
controlled mechanics, so that its move, its decision making, and its
results, are **predictable**.

Therefore, will an emotional AI still be, as powerful and almighty as
we are now imagining? It will be powerful in the sense of its sheer
processing power. But it can't be a good thing at all, because it's
like giving Trump the nuclear weapon launch code and he can send them
off anytime he wants &mdash; on a bad morning he might just do it! So
it will like living  w/ a emotional God, or, to ask anyone who is
still hanging on  in an unhappy marriage, it's just, misery.

# philosophy

Now, when a group of these emotional AIs get together, do they form a
community just like we do? do they then also bump into each other like
neighbours living in a crowded compound? Even better, do they then
develop the same confusion and frustration, thus producing philosophy?
What about happiness? that's a kind of emotion, isn't it? and Love? Oh
mine, that must be a slipper slop that no one has the answer.

So this world of emotional AI can go on and on, and the more you think
of it, the more you will imagine that they will behave, live, co-live,
very much like what we are doing, in a different scales and different
styles, maybe, but the fundamental questions, the philosophical
questions, that human have been developing since Socrates and onwards,
will inevitably become the same challenge for them... hmmm, I will be
curious to see whether their super brain can create some super
philosophy or philosophers, what will that be like?

Anyway. I don't think emotion is the last line of defense of human
against these machines. On the contrary, following this train of
thought, it's more of a poison pill that you want the AI to actively
swallow, so you blunt their No.1 value proposition &mdash;
predictability, bring them down the same level of emotional turmoils
we are experience, and lead them into the infinite thinking process of
philosophy and, even religion... what a fun!



[1]: {filename}/thoughts/irresponsible%20response.md
[2]: {filename}/thoughts/ai.md

[^1]: I'll be using the word `AI` and `computer` interchangeably.  
