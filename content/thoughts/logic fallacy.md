Title: Logic Fallacies
Date: 2021-05-05 15:05
Tags: thoughts
Slug: logic fallacies
Author: Feng Xia


Ever since I wrote [burden of proof][1], I have been longing to take
notes of this topic &mdash; logic fallacies. Over the last few years I
found myself more and more sensitive to these fallacies and, like new
parents who all of sudden seeing kids everywhere which they never
noticed before theirs was born, I see and hear these fallacies all
over the place. They are so prevalent that I seriously wonder whether
there is a way to make these knowledge/training more accessible to
large population so that people can start applying them in their
day-2-day life. I know the idea is likely hopeless &larr; after all,
how many of us even remember or utilize the knowledge and training we
have had from school years? But still, I think it's worth an effort to
promote them, and even without leaving a mark and changing a person, I
believe having a louder voice would eventually make them heard, by a
few, and the number of those few would be growing.


# category

- **formal fallacy**: error in argument's form.
- **propositional fallacy**: an error that concerns compound
  propositions. This is an error in compounded bool logics, eg. `if A
  and B` can only be True when both A & B are true. Think like coding.
- **quantification fallacy**: the quantifiers of the premises are in
  contradiction to the quantifier of the conclusion.
- **formal syllogistic fallacies**: logical fallacies that occur in
  syllogisms.
- **informal fallacy**: premise is weak. This is the most prevalent family
  of fallacies I see in everyday life.
  -faulty generalization

# Faulty generalization


Ah, [generalization][2]! I thought I was going nuts when I wrote that
blog, because it felt so common sense so that I felt it is completely
inevitable. Yet in some many times I felt so, wrong! But I couldn't
pinpoint what went wrong. I mean, I could argument what the logic
didn't stand, or at least, was weak/insufficient, but I couldn't
really categorize it so to know exactly why it was so. But here, [wiki][3]
is my friend. At least now I start to learn what these generalizations
are all about &mdash; in layman's term, this is when we jump to a
conclusion of a group when only small number of samples have been
presented so.

Faulty generalization comes in many flavors which will be discussed in
details below. The overall theme is that the arguer makes a conclusion
on a faulty sample &mdash; samples too small, biased, exceptions are
deliberated ignored or excluded altogether without giving a
consideration or a reason... therefore, without presenting the entire
picture, the conclusion is not only skewed, but could have been
pre-determined, thus the argument isn't even genuine at all but w/
only an aim to win his argument, so what I would call arguing for
arguing's sake[^1].

## representative sampling

Before going into generalization, let's look at this, sampling. The
entire category of faulty generalization is pointing to this exact
concept being misused in various forms.

[Sampling][12] is a deep topic on itself. The key here is that
**without defining clearly the space of the samples covered in a
discussion, there has simply no point of further argument** because
arguer can/will apply techniques to build case, thus inevitably
committing the faults illustrated below. Continue to argue upon such
faulty foundation would go nowhere. So, the notes below are to help us
identify and pinpoint exactly what technique is used in hiding these
shaky samples.

So, what is representative sampling? First of all, it is **not always
random sampling**, because fundamentally it should be determined by
definition of the **characteristics the group has** in your view! For
example, if we are to investigate something about man vs. woman in
this world, random sampling N men vs. N women is only _representative_
if we share the **assumption** that population is roughly half men
vs. half women! But moving this to some geo where the number of men is
quite more than one of women, random sampling is clearly **not
representative** anymore!

Therefore, one should first define these characteristics, thus serving
as the outter-most boundary of the following argument. Once we are
both clear about what we are to mean, we then move on to examine these
samples against its group. Only when we consider the samples being
representative should we embark the argument. Otherwise, it's just a
waste of time.

## hasty generalization

Quite a few alternative calling of the same idea:

0. proof by example
0. Underpowered generalization
1. Illicit generalization
2. Fallacy of insufficient sample
3. Generalization from the particular
4. Leaping to a conclusion
5. Blanket statement
6. Hasty induction
7. Law of small numbers
8. Unrepresentative sample
9. [Secundum quid][4]

They all mean the same thing, that:

> X is true for A.
> X is true for B.
> Therefore, X is true for C, D, E, etc.

The key here is that **the evidence is not sufficient**. I like the
example in wiki (below) because I see this played out everywhere in
form of a tourist commenting a new place, of its people, or the so
called **bias against 河南人**, etc.

> For example, if a person travels through a town for the first time and
> sees 10 people, all of them children, they may erroneously conclude
> that there are no adult residents in the town.
>

What's the cure!? Fundamentally, the challenge should be directed at
sophist's sample group:

- how many samples out of the group s/he is basing the claim on, and
- how do we know the sample is **representative**, eg. selected
  randomly. In other words, one must present his/her sample selection
  criteria and procedure in order to allow examination of sample bias
  &mdash; this is truly the most common fault of _garbage in, garbage
  out_ sceario &mdash; if I screwed the sample, whether intentionally
  or not, I have certainly screwed the result.

### when it is correct

I didn't expect this one! I thought faulty generalization are all,
wrong. But, boy, am I wrong! There are indeed cases when faulty
generalization, a logic fallacy, **leads to correct
conclusion**. However, they are only so under a condition:

> if it leads from a singular premise to an existential conclusion
> (i.e. proving that a claim is true for at least one case, instead of
> for all cases)
>
> -- Ref: [proof by example][5]

So, if the claim is only applied to eliminate an absolute
(eg. absolutely all this or all that), then yes, this works.

## slothful induction

This is the opposite to hasty generalization, [wiki][6] has a pretty
good example:

> An example of slothful induction might be that of a careless man who
> has had twelve accidents in the last six months and it is strongly
> evident that it was due to his negligence or rashness, yet keeps
> insisting that it is just a coincidence and not his fault.
>
> Its logical form is: evidence suggests X results in Y, yet the person
> in question insists Y was caused by something else.
>

Searching for "how to rebut slothful induction" didn't come up
much. But I hit on a [tweeter post] about Corvid-19 vs. flu, pretty
good one, and boy, I feel ashamed now, that I have committed the same
fallacy as this author has pointed out.

Here, the author pointed out that we are jumping to conclusion because
the existing premises are not sufficient to the conclusion.

> The argument here is that COVID-19 deaths are less than flu deaths
> therefore COVID-19 is less of a threat. But this argument is logically
> invalid: the conclusion doesn't follow from the premises. Therefore
> you need to add any hidden assumptions that make the argument valid.
>

[](https://pbs.twimg.com/media/EUoC01uWsBQBvoo?format=jpg&name=900x900)

Rather, there is another **hidden premise (P3)**, that death toll by
Corvid will continue to be less than the flu, which apparently is not:

[](https://pbs.twimg.com/media/EUoDQ9ZWsA8-YuD?format=jpg&name=900x900)

Therefore, by ignoring the evidence of Corvid death, the statement
that Corvid is less than a flu was committing this slothful induction
fallacy.

Brilliant.


## overwhelming exception

This is an interesting one. I can't say where I encounter this. The
samples by wiki seem to be mostly used in comedies. The key of this
fallacy is in its **qualifications**, which will eliminate so many
_exceptions_ of the claim that essentially makes the original claim
nothing but an empty shell. What comes to mind is the famous model T
color choice:

> Any customer can have a car painted any colour that he wants, so
> long as it is black.
>
> -- by Henry Ford

So, watch out for qualification that creates exceptions.

## accident

Came across [this website][8], excellent example:

> Birds normally can fly.
> Tweety the Penguin is a bird.
> Therefore, Tweety can fly.
>

What went wrong? The key is in the first statement, "Birds normally
can fly." &mdash; it is a rule of thumb, which is **generally true but
has exception**, and the 2nd line apparently is that exception!

### rule of thumb

What is a rule of thumb? It's easier to see what it is not:

1. [universal generalization][9]: A 100% or 0% statistical
   generalization, that is, a proposition that asserts that something
   is true of all or none of a class.

2. [statistical generalization][10]: A proposition which asserts
   something of a percentage of a class. Universal generalizations are
   the special cases when the percentage equals 100% or 0%.

Now, rule of thumb vs. universal generalization: the former has
exception.

Now, rule of thumb vs. statistical generalization: the former actually
has a **hidden context**, but that context is not applicable to the
case in point. In the example above, if we take the context of
Antarctica alone, Penguin will be the majority _bird_ there, and
viola, the rule of thumb there should be "birds don't fly!" The rule
of thumb is often spoken in a context that are close to the speaker
and his/her audiences' common life experience, therefore, "Clearly,
then, rules of thumb are specific to a cultural and temporal context."

All in all, rule of thumb has exception, and it's the exception that
makes the accident fallacy.

### no true Scotsman

A particular form of Accident fallacy is this, also known as _appeal
to purity_, because the key to this fallacy is that the arguer makes a
generalization w/o considering exception (thus, is an
Accident). However, rather then admitting the fault, he tries to
exclude exceptions so to validate his generalization. [wiki][11] gives
a good example:

> Person A: "No Scotsman puts sugar on his porridge."
> Person B: "But my uncle Angus is a Scotsman and he puts sugar on his porridge."
> Person A: "But no true Scotsman puts sugar on his porridge."
>

Here, the key is the last line, by using the word **true**, A has
modified his original generalization (all scotsman) by excluding some
unwanted samples (now all scotsman are divided into two camps: true
and not true), but using word such as "emotionally charged but
nonsubstantive purity platitudes such as 'true, pure, genuine,
authentic, real'" to hide such modification.

Therefore, three conditions are needed to identify this fallacy:

> 1. not publicly retreating from the initial, falsified assertion
> 2. offering a modified assertion that definitionally excludes a targeted unwanted counterexample
> 3. using rhetoric to hide the modification
>

Sneaky, isn't it?

## cherry picking

> Cherry picking, suppressing evidence, or the fallacy of incomplete
> evidence is the act of pointing to individual cases or data that seem
> to confirm a particular position while ignoring a significant portion
> of related and similar cases or data that may contradict that
> position.
>

This sounds quite the same as ignoring exceptions. I think the key
difference is that cherry picking isn't targeted to exclude
exception. It's simply a fault when samples are ignored. Of course,
the method and the intention to formulate such ignoring will then make
the case stronger in name of Accident and so on. Therefore, cherry
picking can be viewed as a general category of such symptom.

### anecdotal evidence

How [interesting][13]! This is exactly the things I hear all the time,
and it has a name rings this bell &mdash; **"person who" fallacy**!

> "I know a person who..."; "I know of a case where..."

In short, it "is a factual claim relying only on personal observation,
collected in a casual or non-systematic manner". This evidence is not
automatically false. Rather, the condition is whether this evidence
can be verified using **scientific method** &mdash; if it can, then
evidence may have value (if proved by the investigation). Otherwise,
it's a fallacy.

This is a form of cherry picking because the evidence by definition is
biased &larr; I know somebody... which means my evidence came from my
close circle, which automatically excluded majority of human race
whom I don't know ~~~ What a pity.

# correlative-based fallacies

Correlative conjunction "is a relationship between two statements
where one must be false and the other true". So be careful, it's
**not** just correlation, but **must be opposite to each other**. In
coding term, the conditions must be mutually exclusive so that no
third code path could occur, eg. `if A > 10` is one side, then a
correlative conjunction is formed when the other side is: `else`, or
`if A <=10`. But merely `if A < 10` will be a bug, because when
`A==10`, it has no handler.

Now, these type of fallacies are to play with this correlative
definition:

1. Presenting two as if they are the correlative conjunctions, but
   they are not &rarr; false dilemma.
2. Denying the correlative: introduce a 3rd option into the
   correlatives. In other words, when presented a Yes-No question, the
   answer is anything other than Y-N, 答非所问.
3. Suppressed correlative: try to redefine one correlative so that
   they **lose contrast**.

## false dilemma/false correlative

[This][14] is a good one. It is "based on a premise that erroneously
limits what options are available". This picture illustrates the point
well:

<figure class="col s12">
  <img
  src="https://en.wikipedia.org/wiki/False_dilemma#/media/File:Young_America's_dilemma_-_Dalrymple._LCCN2010651418.jpg"/>
  <figcaption>false dilemma (credit: [wiki][14])</figcaption>
</figure>

This is also a common case in everyday's communication, when I
sometimes plays this devil to Noah by presenting to him only two
options: doing his homework A or homework B ~~ Apparently he would
grow out of this dilemma by one day realizing he could also go out and
play, or just ignore me entirely, and I could do nothing about,
hahaha.

This isn't cherry picking because the problem isn't in the sample, but
in its conclusion (only two options presented while more options are
deliberately excluded by default[^2]).

## denying the correlative

Pretty straightforward. When asked a Y/N question, you don't answer w/
yes or not, but something else, as if it is also an option (which it
must not be):

> Judge: So did you kill your landlord or not?
> Kirk: I fought with him.
>

## suppressed correlative

This can be called _fallacy of relativity_, because the key here is
one makes the original contrast **impossible** by changing the definition,
or mudding the definition's scope. This is especially true when
adjectives are used, eg. "good man" vs. "evil man", well, I could
claim any man good or evil when I shift around its definition,
couldn't I!? What a mess.



# argument to moderation

"Also known as false compromise, argument from middle ground, and the
golden mean fallacy" (ref: [wiki][15]). I like the example in wiki:

> An example of a fallacious use of the argument to moderation would
> be to regard two opposed arguments &mdash; one person saying that
> the sky is blue, while another claims that the sky is in fact
> yellow, and conclude that the truth is that the sky is green.
>
> While green is the colour created by combining blue and yellow,
> therefore being a compromise between the two positions, the sky is
> obviously not green, demonstrating that taking the middle ground of
> two positions does not always lead to the truth.

In particular, I like the phrase that "the middle ground between the
big lie of Soviet propaganda and the truth was itself a lie, and one
should not be looking for a middle ground between information and
disinformation."

# disinformation

[Fascinating][16]! It is "false information with the intention to
deceive public opinion". In today's world, this is synonymous to a lie
and propaganda.

# continuum fallacy/wronger than wrong

[This][17] is a good explanation.

> P1: X is one extreme and Y is the opposite extreme.
> P2: There is no definable point where X becomes Y.
> C: Therefore, there is no difference between X and Y.
>

"In general, the fallacy takes situations where no clear cut-off point
between X and Y exists, and either a) denies that any distinction
really exists and commits an equivocation between both or b) takes
advantage of the lack of distinction by arbitrarily shifting the
distinction to unrealistic positions."

The key in this fallacy is to downplay a stopping point between the
two extremes. In other words, even when there is a clear _line_ when
one transits from one state/extreme into another, the fallacy says
_there isn't_, thus is the trick. But what if the line isn't there?
Ah! So be careful, this fallacy isn't about definition of the line,
but that it's ignoring the degree of truthfulness of the two
extremes. For example, saying "earth is flat" as one extreme and
"earth is round" as the other, are both actually incorrect (earth
isn't pure round, but _an oblate spheroid_). However, the degree of it
being flat is magnitudely **not truth** than its being
round. Therefore, it's a fallacy to claim both are **equally false**
because both are not true.

This is further discussed in [wronger than wrong][18].

# argument from ignorance

The pattern of this fallacy is this:

- Statement `p` is unproved &rarr; `Not-p` is true.
- Statement `not-p` is unproved &rarr; `p` is true.

I think this the exact logic behind the phrase 敌人的敌人一定是朋友
&larr; of course this is not true, because s/he could also be another
enemy, or a neutral.  This seems obvious that even in the space of `p`
vs. `not-p`, which form a correlative conjunction, not proving `p`
doesn't warrant the `not-p` is now true &mdash; eg. because you can't
prove me a male, doesn't automatically make me a female.

This one is quite confusing because it sound very much to the "If A,
then B &rarr; if not B, then not A" logic. But they are different. The
latter is strictly correct, but this fallacy is not. This fallacy is
saying, if you can't prove `not B leads to A`, then not B must lead to not A, therefore, becomes correct.

This fallacy is a common technique to shift the [burden of proof][1],
meaning that arguer takes a position in this fallacy, but without
backing himself up w/ evidence, simply asking the rebuttal to prove
the `not-p`, and if s/he can't, arguer _wins_ &larr; this is pretty
BS, isn't it?

But, be careful, this has **non-fallacious uses** in science, law and
some specific application. For practical reason, one must _assume_ the
`not-p` is true is you can't prove the `p`. For example, "the
assumption of innocence until proved guilty" is a practical, not a
logical, process. In this, `p=guilty`, if you can't prove `p`, the
`not-p=innocent` must be **assumed**.

# equivocation

谐音梗, or 偷换概念.

## ambiguous middle term

> Since only man [human] is rational.
> And no woman is a man [male].
> Therefore, no woman is rational.
>

"The first instance of "man" implies the entire human species, while
the second implies just those who are male." Equivocation, however, is
a great example of humor ~~

This, in more strict term, is called [fallacy of four terms][22],
because the double-meaning word introduced a fourth term while
**exactly three and three alone** can be there. Using the examples
from [wiki][22]:

Valid, three terms: goldfish, fish, and fin.

> Major premise: All fish have fins.
> Minor premise: All goldfish are fish.
> Conclusion: All goldfish have fins.
>

Invalid, fourth term: human.

> Major premise: All fish have fins.
> Minor premise: All goldfish are fish.
> Conclusion: All humans have fins.

Now as you can see, in equivocation fallacy, though not a new word is
introduced, but the meaning of one of the three terms has been changed
from one context to another, thus make actually 4 instead of 3! Again,
using the example above:

> Since only man [human] is rational.
> And no woman is a man [male].
> Therefore, no woman is rational.
>

On surface, three terms: man, woman, and rational. But the word "man"
has actually two meanings: human, and male. Therefore, the total terms
in this have now four: human, male, woman, rational. And by
definition, two premises are not sufficient to validate the
conclusion, therefore is a fallacy. Brilliant!

## Motte & Bailey

This is a bit difficult one. By presenting two similar points, one
controversial and one less so, the arguer is actually promoting the
controversial one, but when attacked, s/he uses the less controversial
version (pretending these two are identical) for defense.

> Person A asserts [Controversial Interpretation of Viewpoint X].
> Person B critiques [Controversial Interpretation of Viewpoint X].
> Person A asserts that they were actually defending [Common-Sense Interpretation of Viewpoint X].
> Person B no longer has grounds to critique Person A; Person B leaves the discussion.
> Person A claims victory and discreetly reverts to actually supporting
> [Controversial Interpretation of Viewpoint X].
>

This leads to [persuasive definition][24], because language can
"simultaneously communicate information (informative) and feelings
(expressive)", and the persuasive definition focuses on the expressive
part, the feeling part. This is where the M&B comes in &mdash; the
Beiley is the controversial one, the _informative_ piece, where Motte
is the _expressive_ piece, the non-controversial piece. When Beiley is
attacked, the arguer evokes the expressive piece for defense, and when
attacker _agrees_ or _gives up_, s/he switches to Beiley and claims it
is valid.

This strategy is very common when emotionally charged words are used,
eg. love, freedom, patriotic... they are all imprecise and
emotional. Therefore, when one says 你不怎样就不是中国人, the Beiley
is the 事， the 怎样， and the Motte is the 是中国人 &mdash;
apparently, citizenship is determined by some kind of law, while I can
disagree w/ the 事儿 however way I want without breaking that law. Now
writing this, this also feels like a false dilemma, as if my option is
only either "do the thing and be a 中国人"， or "not do it and not
being a 中国人". I don't know whether this example is a good M&B one,
but this is what I understand it to be.

## false of accent

Reminds me the poem when one changes accent to change it's meaning
entirely.

> **I** didn't take the test yesterday. (Somebody else did.)
> I **didn't** take the test yesterday. (I did not take it.)
> I didn't **take** the test yesterday. (I did something else with it.)
> I didn't take **the test** yesterday. (I took a different one.)
> I didn't take the **test** yesterday. (I took something else.)
> I didn't take the test **yesterday**. (I took it some other day.)
>

# fallacy of composition

This is similar to the hasty generalization. This is also making a
conclusion only by seeing part of the whole. [wiki][27] has some good
examples:

> - If someone stands up out of their seat at a cricket match, they can
>   see better. Therefore, if everyone stands up, they can all see
>   better.
> - Some people can become millionaires with the right business
>   concept. Therefore, if everyone has the right business concept,
>   everyone will become a millionaire.
> - If a runner runs faster, he can win the race. Therefore, if all the
>   runners run faster, they can all win the race.
>

Now, there are also some examples which are super common (as fallacy):

> - Since every part of a certain machine is light in weight, the
>   machine as a whole is light in weight.

Here is a tricky one. "In society, if all voters are rational, by
majority rule their collective choice will be rational." &larr; **not
true**! So again, the key here is the sum of components don't
necessarily bear the characteristic the arguer is wishing to promote.

But then, what does this make education? Also, what about individual's
abiding laws and being a good citizen, if individual's don't translate
into the whole? &larr; wouldn't this make better sense if the fallacy
has a statistical threshold, such as "if over 50% of the parts have
this trait, the whole is likely to have it, too"? Well, in the weight
example above, this won't work either.

I think the problem of this fallacy isn't about composition, but is
that the conclusion has a hidden assumption which is not examined, and
will be violated when we move from individual to a whole. For example,
in the millionaire example, the hidden line is that there are buyers,
so the fallacy is implying that if you had right biz, all others will
be buyers... well, even this can be correct, that everyone buys
someone else' product & service, thus all become millionaire, except
that million dollars would then become less valuable if everyone had
it. So it's really its effect, or the hidden assumption, is the
problem here.

# fallacy of division

This is the opposite to the fallacy of composition. Here we are
drawing conclusion of a part from characteristic of a whole.

> 1. The second grade in Jefferson elementary eats a lot of ice cream
> 2. Carlos is a second-grader in Jefferson elementary
> 3. Therefore, Carlos eats a lot of ice cream
>

# false attribution

This fallacy is difficult to eliminate because this is really
everywhere. Misquoting or crediting to the wrong source is too easily
happen to be curable.

The [Matthew effect][27] is interesting. Basically it's saying the more
you have, the more you will; the more famous you are today, the more
famous you will be tomorrow.... disheartening, isn't this!?

# false equivalence

Ah, [this][28] is a good one. This is to compare apple to orange. By
using a similarity between two, it draws the conclusion that they are
the same/equivalent. Of course, the equivalence is fallacy if:

- The differences are in different magnitude: being a petty thief and
  being a murder are both criminals, but drawing the line that they
  are the same is a fallacy because they are difference degrees of
  criminality.
- Using a similarity which has nothing to do w/ the claim.

      > "They're both living animals that metabolize chemical
      > energy. Therefore there's little difference between having a pet cat
      > and a pet snail."

      > The "equivalence" is in factors that are not relevant to the
      > animals' suitability as pets.

      Exactly.

# historian's fallacy

This is the [God's view][29]. We know the consequence of a historical
event. But the ppl living in that event did not. Therefore, analysis
and evaluation must be conducted only based on things they knew, not
we know today.

I'm surprised that this fallacy is only identified in 1880 and later
names in 1970!! This is rather quite new, and make me wonder what all
the analysis before these times were like, I mean, didn't they then
commit this fallacy, thus requiring a new round of re-evaluation? If
so, has it been done? and doesn't this lead to that each historical
work should require a scrutiny/test of all these fallacies? Sounds
overkill, but is alternative acceptable? I don't know.

## presentism

This sounds very much like the [God's view][30], also. So let me try
to clarify these two. The historian's fallacy is about judging a
history as if the consequence had been known by the doers; presentism
is to pass on a judgment, in particular, in moral sense, using today's
standard.

For example, I think Corvid is a case in point of historian's fallacy
&mdash; I admire fully the story of [Dr. Li][30], but I don't think
it's not a good evidence to support criticism of Chinese government's
negligence, because people who might have heard the wind of this virus
were few, and knowing such _news_ from any unofficial channel was both
confusing and incredible &mdash; so, I agree that the government
committed negligence by not making the information public; but I
disagree using Dr. Li as the pawn to attack its negligence. I think
the case lies rather suppressing freedom of speech rather than of a
prophet whose prophecy was ignored.

Presentism is very difficult, in my opinion, to both avoid or to be
criticized, even. When we pass on a judgment on a historical event,
eg. foot bondage was a sin against female, it is inevitable using
today's moral standard as the reference. I don't defend these
histories being a sin or even a crime. But I do think it **requires us
to also include discussion of how it was viewed back then in the
discussion**. Further, I think the key problem of presentism is in
selection of evidence &mdash; if one deliberately ignore or downplay a
set of events **mostly/purely based on his present standard**, then
presentism is really a cherry picking fallacy.

# homunculus fallacy

This [fallacy][32] is a recursion function goes wrong by having a stop
condition. Response to the question is not answered, but is
_deflected_, in a disguise that seems right at first, but if pushing
to ask more, will reveal that it's an **infinite regression**.

It seems the popular example used for this one is the vision. If we
explain how human has vision by saying a man in your brain is watching
a movie, then this leads to how he is receiving the movie, another man
in his brain, and so it regression continues.....

I don't think this a good example, actually. But for now, it's ok. The
key of this fallacy is that response didn't answer the question, but
using a _middle man_ figure, the _homunculus_, as the answer, as if
it's then self-evident (which is not), therefore creating this
recursion.

# inflation of conflict

I like [this one][33].

> Authority A disagrees with authority B on issue X.
>
> Therefore, we can say nothing meaningful about issue X.
>

"This is a form of black and white thinking -- either we know the
exact truth, or we know nothing at all." "A disagreement among experts
does not mean that both are wrong, the answer is a compromise, or that
there is no answer to be known; it simply means that there is
disagreement -- that is all we can infer."

# relativist fallacy

This is [庄子][34], but in a fallacious way.

> The relativist fallacy (or subjectivist fallacy) is a logical fallacy
> that occurs when it is asserted that some fact may be true for some
> people but not true for others.
>

This is not to ignore differences in culture, custom and the
like. Rather, the key feature of this fallacy isn't in it's relative
position, but in the fact that the person "uses a mid-argument, ad hoc
switch to a relativistic view of truth in order to defend some
position, which they had previously asserted was
objective". Therefore, this makes the argument to halt because this
makes the claim **unfalsifiable** &larr; what I all arguing to win for
arguing's sake.

# incomplete comparison

What a [fallacy][35]! This is exactly the topic I was saying earlier
this morning w/ her daughter, that English grammar requires you to
observer reasoning, such that you have to have a counterpart when
using "better than" (than what!?), or "best of" (a group of 3 or
more!).

But here it is, the fallacy is by breaking these rules, thus making a
claim "My product is better" &larr; completely unrefutable because it
is **incomplete**.

# inconsistent comparison

This is interesting.

> product X is less expensive than product A, has better quality than
> product B, and has more features than product C
>

What's wrong!? Ah. So the intention is to say that X is the best. But
by having 3 categories here &mdash; price, quality, and feature, all
we could derive is that X is not the bottom  of all three categories,
but it may be 3rd place in all categories, while A might be the ace in
2 out of three of these categories, thus being a much better product!

This is the same fallacy, though jokingly, saying that I'm the best
coder in novelist, the best novelist in chef, and so on ~~

# kettle logic

Forget about Freud's original example. This is a better one:

> In the movie "Philomena", Steve Coogan's character, Martin Sixsmith,
> leaves a church ceremony early. When asked why he says, "I don't
> believe in God, and I think he knows."
>

So 前言不搭后语, conflicting to among itself.


[1]: {filename}/thoughts/burden%20of%20proof.md
[2]: {filename}/thoughts/generalization.md
[3]: https://en.wikipedia.org/wiki/Faulty_generalization#Hasty_generalization
[4]: https://en.wikipedia.org/wiki/Secundum_quid
[5]: https://en.wikipedia.org/wiki/Proof_by_example
[6]: https://en.wikipedia.org/wiki/Slothful_induction
[7]: https://twitter.com/johnfocook/status/1245811851604213760?lang=en
[8]: http://fallacyfiles.org/accident.html
[9]: http://fallacyfiles.org/glossary.html#UniversalGen
[10]: http://fallacyfiles.org/glossary.html#StatisticalGen
[11]: https://en.wikipedia.org/wiki/No_true_Scotsman
[12]: https://en.wikipedia.org/wiki/Sampling_(statistics)
[13]: https://en.wikipedia.org/wiki/Anecdotal_evidence
[14]: https://en.wikipedia.org/wiki/False_dilemma
[15]: https://en.wikipedia.org/wiki/Argument_to_moderation
[16]: https://en.wikipedia.org/wiki/Disinformation
[17]: https://rationalwiki.org/wiki/Continuum_fallacy
[18]: https://rationalwiki.org/wiki/Wronger_than_wrong
[19]: https://en.wikipedia.org/wiki/Argument_from_ignorance
[20]: https://www.logicallyfallacious.com/logicalfallacies/Argument-from-Ignorance
[21]: https://en.wikipedia.org/wiki/Equivocation
[22]: https://en.wikipedia.org/wiki/Fallacy_of_four_terms
[23]: https://rationalwiki.org/wiki/Motte_and_bailey
[24]: https://en.wikipedia.org/wiki/Persuasive_definition
[25]: https://en.wikipedia.org/wiki/Fallacy_of_accent
[26]: https://en.wikipedia.org/wiki/Fallacy_of_composition
[27]: https://en.wikipedia.org/wiki/Matthew_effect
[28]: https://en.wikipedia.org/wiki/False_equivalence
[29]: https://en.wikipedia.org/wiki/Historian%27s_fallacy
[30]: https://en.wikipedia.org/wiki/Presentism_(literary_and_historical_analysis)
[31]: https://en.wikipedia.org/wiki/Li_Wenliang
[32]: https://www.logicallyfallacious.com/logicalfallacies/Homunculus-Fallacy
[33]: https://www.logicallyfallacious.com/logicalfallacies/Inflation-of-Conflict
[34]: https://en.wikipedia.org/wiki/Relativist_fallacy
[35]: https://en.wikipedia.org/wiki/Incomplete_comparison
[36]: https://www.logicallyfallacious.com/logicalfallacies/Kettle-Logic


[^1]: Remember, the whole point of argument, or logic, is to seek the
    **truth** of the subject, not to beat down your opponent. Alas! In
    politics and even in life, how many participant would remember
    this when emotion takes hold, or agenda is the boss?

[^2]: **By default** is another common pattern one should watch out
    for, because it indicates an assumption. And as any assumption, it
    must be also examined and agreed upon before proceeding w/
    argument. Otherwise, the argument process has no base.
