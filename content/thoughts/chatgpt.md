Title: ChatGPT
Date: 2023-03-18 13:16
Tags: thoughts
Slug: chapgpt
Author: Feng Xia

<figure class="col s12">
  <img src="images/DSC_1406.JPG"/>
</figure>


The ChatGPT is all over the internet these days. Had a long discussion
yesterday, and it's becoming clearer and clearer to me that this is
nothing but another hype, and I could say this is going to be a short
one, too. NPR's view on this is right on the mark, I think, that
chatgpt is a mirror of our past &mdash; in other words, it is
"perpetuating" what we have said about a thing. In my word, it is a
library or Google on steroid. It does make accessibility to these
_text_ easier, but it also highlight more and more that the bottleneck
of this entire **knowledge chain**, which used to be bounded by the
exclusiveness of text books and/or domain knowledge, are now
completely determined by the limited capacity of human brain &mdash;
just like so called drinking from a firehose, or giving someone your
source code.. does it contain all the IPs you want to protect, yes,
very much so, but it's also an illusion that anyone who possess this
code would be now on the same footing with you who may have been
working on it for the last 2 months or years. I think the hype around
ChatGPT is yet another case highlighting how easily we are willing to
discard the value of experience (not that I'm now older thus defending
the value of so called "experience", but I have lived through enough
positive & negative cases of this topic so to now understand why it is
valuable and when it is valuable) in face of a shining new kid around
block. while writing this I start to even wonder whether human as a
whole is indeed the "curiosity kills the cat"? I used to think women
in particular are _vulnerable_ to this trait, but now with the
technology waves come and go in the last few years &mdash; blockchain,
AI, machine learning, now ChatGPT, I deep feel these waves are
arousing the exact same reaction, which then leads me to believe the
same reaction is a built-in character of these human... in other
words, it is not the new _drug_ is any better or worse than the
previous one, it's that this drug causes the same kind of _high_, and
one is relatively quicker to cause the effect than the other, maybe.

So indeed what we are witnessing is not yet another technology which
leads to the future. On the contrary it is a new drug on the market of
which we, the opiate addicts, are now getting high from. Do we really
care which drug to take if they are giving the same sensation in the
end? And further, is then this new drug any _better/worse_ than the
other one? If looking under this light one would reasonable argue that
there must be certainly a relatively position between the two, or any
two, different offerings, whereas one represents a less risk to human,
whether in the physical sense or spiritual sense, than the other
one. However, this logic only holds when we discuss it within a
boundary, for example, that these drugs don't kill me, or damage me to
a degree is a health hazard. I know the threshold of the **harzard**
is up to debate. Indeed, where we draw the line as being _acceptable_
is the tricky shot, always. So along this line, if the two drugs can
kill me in a equally measure, well, even on this aspect it's difficult
to categorize the two being equal or not &mdash; think of the WWII's
gas chamber in which Nazis created such a **super drug** which get a
life eliminated in two seconds vs. some other ways described in
classic literature. So it is, in this sense, better, a progress. But
then, isn't it strange if two now develop a discussion that my way is
better in killing than another? If you were given the task to do just
that, yea it makes total sense and very practical and even
necessary. But at the mean time we could present many other aspects of
the same act that not only it's irrelevant one way of killing is
"better", but the whole idea is simply, wrong!

Now let's talk about the common _scare_ that so and so will now
replace your job. Doesn't it sound familiar? Of course. There is
nothing new about such scare, historically or recent. I have had a
bump year in my career, but I failed to see any connection between a
new technology, new programming trend, and my job loss. Actually the
fundamental logic train of such scare is simply wrong. The way it goes
is "If you have skill A, you will have a job; else, you don't."
... but this is a logic fallacy!!! Two problems here. First of all,
skill A is not sufficient. There is logical guarantee at all that
having a skill A will lead to a job. Plenty examples in life regarding
this.  Second, if we temporarily accepting that "A &rarr; B", then
"not A &rarr; not B" will be true, "I don't have a job because I don't
have skill A"... this is even more obvious than the original
form... you could have million reasons not having a job, deficiency in
skill A is just option on a long selection list.

Many posts are titled "ChatGPT will obsolete frontend engineering",
and examples of asking it to write a table, and viola, it gives back a
nicely written React code which works perfectly. Great? Not at all. I
have long argued that Google is as smart as the question you ask. Same
applies here. If I could have broken down a feature in such a
level of detail and described the intended implementation clearly, I
bet I could have found a code snippet by Googling which is equally _good_ as
the chatgpt feedback. The so called search-engine-oriented programming
is in play here. But, just like the piece you found in Google, you
copy & paste it in to yours, run it, what's the odds it works out of
box? In my experience, minimal!!!! ... just like I always question
someone who pieces a few blog info together in a PPT and claims it
will work because the blog says so!!!... the reality is much harsher
than this. Copy & paste is nearly a given in today's engineering
work. Not many people have the capability to **reinvent the wheels**,
and not many's job need to. 99% of the people are **integration
engineers** &mdash; they copy & paste code from here and there, and
glue together in some fashion so that it achieves what s/he wants to
achieve. Think of how many third-party code your project actually
requires! I could safely bet that in any project these days, less than
10% of the final product is **original**, it can't be higher, and it
needs not be higher. Integration is to say we are standing on shoulder
of the giants, but the standing itself is much much more challenging
than many realize!!

So again, chatgpt's code requires my brain to read, to understand, and
likely to tweak so it will fit into my _legacy_ code, so the amount of
workload my brain needs to take hasn't changed. Well, asking any
programmer how s/he enjoys reading someone else's code? I mean, how
many people even likes reading an operator manual? These _example
code_ are exactly that, a manual, that shows you can do this this way,
but it guarantees nothing of its validity, and certainly nothing of
its connection to your code (well, it doesn't know your code, doesn't
it? So as cliche, it doesn't know what it doesn't know)... so these
examples are absolutely nonsense! It equals to you ask a saint "what I
should do next" without having him/her know anything about your
situation... then this person just spills out an answer "go
west"... how credible is that!? You gotta be insane to jump to action
based on that.

In [1][this blog] I have reflected the value of technology &mdash;
transparency, efficiency, and accountability. I think Google and
ChatGPT has achieved nice progress in the first two categories. But we
haven't done enough in the last one. I fear these tools are making too
great a progress in constructing a positive feedback loop of
information, but little in a negative feedback. And as a common sense
of a positive feedback loop, such system is not stable.

So, what will this society to become!?

[1]: {filename}/thoughts/reflection%20on%20technology.md
